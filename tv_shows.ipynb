{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import kaggle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-e2e030d6a1b1>, line 10)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-e2e030d6a1b1>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    kaggle.api.dataset_download_files('unanimad/emmy-awards', path='./data/awards', unzip = True)]\u001b[0m\n\u001b[0m                                                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "kaggle.api.authenticate()\n",
    "\n",
    "# https://www.kaggle.com/oscarfry/tvtime-shows?select=tvtimeshows.csv\n",
    "kaggle.api.dataset_download_files('oscarfry/tvtime-shows', path='./data/tvtimeshows', unzip = True)\n",
    "\n",
    "# https://www.kaggle.com/ruchi798/tv-shows-on-netflix-prime-video-hulu-and-disney \n",
    "kaggle.api.dataset_download_files('ruchi798/tv-shows-on-netflix-prime-video-hulu-and-disney', path='./data/streamings', unzip = True)\n",
    "\n",
    "# https://www.kaggle.com/unanimad/emmy-awards\n",
    "kaggle.api.dataset_download_files('unanimad/emmy-awards', path='./data/awards', unzip = True)]\n",
    "\n",
    "# https://www.kaggle.com/unanimad/golden-globe-awards\n",
    "kaggle.api.dataset_download_files('unanimad/golden-globe-awards', path='./data/awards' , unzip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tvtime = pd.read_csv('data/tvtimeshows/tvtimeshows.csv')\n",
    "# df_tvtime.head()\n",
    "\n",
    "df_streamings = pd.read_csv('data/streamings/tv_shows.csv')\n",
    "# df_streamings.head()\n",
    "\n",
    "df_award_emmy = pd.read_csv('data/awards/the_emmy_awards.csv')\n",
    "# df_award_emmy.head()\n",
    "\n",
    "df_award_goldenglobe = pd.read_csv('data/awards/golden_globe_awards.csv')\n",
    "# df_award_goldenglobe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                             name      season  \\\n0                           20/20   SEASON 36   \n1  America's Funniest Home Videos   SEASON 24   \n2                      The Assets         NaN   \n3        The Astronaut Wives Club  Starts tbd   \n4                    The Bachelor   SEASON 18   \n\n                                 status tv_network   ano  \n0                          Renewed 5/13        ABC  2013  \n1                           Renewed 5/9        ABC  2013  \n2       Canceled 1/10 after 2 eps aired        ABC  2013  \n3  Delayed to 2015 for creative reasons        ABC  2013  \n4                           Renewed 5/9        ABC  2013  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>season</th>\n      <th>status</th>\n      <th>tv_network</th>\n      <th>ano</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20/20</td>\n      <td>SEASON 36</td>\n      <td>Renewed 5/13</td>\n      <td>ABC</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>America's Funniest Home Videos</td>\n      <td>SEASON 24</td>\n      <td>Renewed 5/9</td>\n      <td>ABC</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The Assets</td>\n      <td>NaN</td>\n      <td>Canceled 1/10 after 2 eps aired</td>\n      <td>ABC</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The Astronaut Wives Club</td>\n      <td>Starts tbd</td>\n      <td>Delayed to 2015 for creative reasons</td>\n      <td>ABC</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Bachelor</td>\n      <td>SEASON 18</td>\n      <td>Renewed 5/9</td>\n      <td>ABC</td>\n      <td>2013</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df_tvstatus = pd.read_csv('status/metacritic.csv')\n",
    "df_tvstatus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def networks_more_popular(df_tt, networks): \n",
    "    column_names = list(df_tt.columns)\n",
    "    df_most_popular = pd.DataFrame(columns = column_names)\n",
    "    for i in networks:\n",
    "        df = df_tt[df_tt['tv_network'].str.contains(i, flags=re.IGNORECASE, regex=True, na=False)]\n",
    "        df_most_popular = df_most_popular.append(df,ignore_index=True)\n",
    "        df_most_popular['tv_network'] = np.where(df_most_popular['tv_network'].str.contains(i, flags=re.IGNORECASE, regex=True, na=False),i,df_most_popular['tv_network'] )\n",
    "    return df_most_popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_networks = [ \"ABC\", \"CBC\", \"NBC\", \"NETFLIX\", \"AMAZON\", \"DISNEY\", \"HULU\", \"HBO\", \"CRUNCHYROLL\", \"GLOBO\", \"APPLE\", \"FOX\", \"MTV\",'FX','CBS','SYFY','THE CW','FREEF','TNT','IFC','STRZ','TVL','SHOWTIME','AMC','USA']\n",
    "df_tvstatus_popular = networks_more_popular(df_tvstatus,popular_networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_status(df): \n",
    "    column_names = list(df.columns)\n",
    "    column_names.append('changed_network')\n",
    "    df_clean = pd.DataFrame(columns = column_names)\n",
    "    df_clean = df\n",
    "    df_clean['changed_network'] = False\n",
    "\n",
    "    #canceled\n",
    "    df_clean['status'] =  np.where(df_clean['status'].str.contains('CANCELED', flags=re.IGNORECASE, regex=True, na=False),'CANCELED',df_clean['status'] )\n",
    "    df_clean['status'] =  np.where(df_clean['status'].str.contains('order rescinded', flags=re.IGNORECASE, regex=True, na=False),'CANCELED',df_clean['status'] )\n",
    "    df_clean['status'] =  np.where(df_clean['status'].str.contains('Likely to end', flags=re.IGNORECASE, regex=True, na=False),'CANCELED',df_clean['status'] )\n",
    "    df_clean['status'] =  np.where(df_clean['status'].str.contains('won\\'t air', flags=re.IGNORECASE, regex=True, na=False),'CANCELED',df_clean['status'] )\n",
    "    df_clean['status'] =  np.where(df_clean['status'].str.contains('Pulled from schedule', flags=re.IGNORECASE, regex=True, na=False),'CANCELED',df_clean['status'] )\n",
    "\n",
    "    #renewed\n",
    "    df_clean['status'] =  np.where(df_clean['status'].str.contains('Renew' , flags=re.IGNORECASE, regex=True, na=False),'RENEWED',df_clean['status'] )\n",
    "    df_clean['status'] =  np.where(df_clean['status'].str.contains('order' , flags=re.IGNORECASE, regex=True, na=False),'RENEWED',df_clean['status'] )\n",
    "\n",
    "    #renewed but changed network\n",
    "    df_clean.loc[df_clean['status'].str.contains('mov' , flags=re.IGNORECASE, regex=True, na=False),'changed_network'] = True\n",
    "    df_clean['status'] =  np.where(df_clean['status'].str.contains('mov' , flags=re.IGNORECASE, regex=True, na=False),'RENEWED',df_clean['status'] )  \n",
    "\n",
    "    #delayed\n",
    "    df_clean['status'] =  np.where(df_clean['status'].str.contains('Delayed' , flags=re.IGNORECASE, regex=True, na=False),'DELAYED',df_clean['status'] )\n",
    "\n",
    "    #end\n",
    "    df_clean['status'] =  np.where(df_clean['status'].str.contains('Ending' , flags=re.IGNORECASE, regex=True, na=False),'END',df_clean['status'] )\n",
    "    df_clean['status'] =  np.where(df_clean['status'].str.contains('ended' , flags=re.IGNORECASE, regex=True, na=False),'END',df_clean['status'] )\n",
    "    df_clean['status'] =  np.where(df_clean['status'].str.contains('Final season' , flags=re.IGNORECASE, regex=True, na=False),'END',df_clean['status'] )\n",
    "    df_clean['status'] =  np.where(df_clean['status'].str.contains('miniseries' , flags=re.IGNORECASE, regex=True, na=False),'END',df_clean['status'] )\n",
    "\n",
    "   # Não tem Info\n",
    "    nationality = ['Brazilian' , 'Spanish', 'German', 'Korean', 'Japanese', 'Swedish', 'French', 'Argentinian', 'Austalian', 'British', 'Belgian', 'Polish', 'Chinese', 'Italian', 'Mexican', 'Indian', 'Colombian', 'Thai', 'Taiwanese', 'Turkish', 'Norwegian', 'Lebanese', 'Israeli', 'Arabic', 'Dutch', 'Argentine','UK','Irish','USA', 'Australian', 'Philippine', 'Canadian', 'Russian', 'South African', 'Danish']\n",
    "\n",
    "    for i in nationality:\n",
    "       df_clean['status'] =  np.where(df_clean['status'].str.contains(i , flags=re.IGNORECASE, regex=True, na=False), 'NAN',df_clean['status'] ) \n",
    "\n",
    "    return(df_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                             name      season    status tv_network   ano  \\\n0                           20/20   SEASON 36   RENEWED        ABC  2013   \n1  America's Funniest Home Videos   SEASON 24   RENEWED        ABC  2013   \n2                      The Assets         NaN  CANCELED        ABC  2013   \n3        The Astronaut Wives Club  Starts tbd   DELAYED        ABC  2013   \n4                    The Bachelor   SEASON 18   RENEWED        ABC  2013   \n\n   changed_network  \n0            False  \n1            False  \n2            False  \n3            False  \n4            False  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>season</th>\n      <th>status</th>\n      <th>tv_network</th>\n      <th>ano</th>\n      <th>changed_network</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20/20</td>\n      <td>SEASON 36</td>\n      <td>RENEWED</td>\n      <td>ABC</td>\n      <td>2013</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>America's Funniest Home Videos</td>\n      <td>SEASON 24</td>\n      <td>RENEWED</td>\n      <td>ABC</td>\n      <td>2013</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The Assets</td>\n      <td>NaN</td>\n      <td>CANCELED</td>\n      <td>ABC</td>\n      <td>2013</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The Astronaut Wives Club</td>\n      <td>Starts tbd</td>\n      <td>DELAYED</td>\n      <td>ABC</td>\n      <td>2013</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Bachelor</td>\n      <td>SEASON 18</td>\n      <td>RENEWED</td>\n      <td>ABC</td>\n      <td>2013</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "df_tvstatus_popular_cleaning = standardize_status(df_tvstatus_popular)\n",
    "df_tvstatus_popular_cleaning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tvstatus_popular_cleaning['tv_network'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['RENEWED', 'CANCELED', 'DELAYED', nan,\n       '1st season in ABC primetime',\n       'Season cut to 10 episodes on 10/23', 'END',\n       'New version of classic game show', 'Postponed to summer',\n       'Banished to Saturdays effective 7/8',\n       \"Sneak preview aired in March;  returns later in '18\",\n       'Fate uncertain; not included in 2014-15 schedule',\n       'Not on schedule; likely will never air', 'Variety show', 'NAN',\n       '2nd season already in production',\n       'Continuation of 2000-07 WB/CW series', 'Anime',\n       'Two-part season (part 2 date is tbd)', 'Documentary series',\n       'Both seasons will stream at once',\n       \"Revival of classic children's show\", 'Animated series',\n       'Finnish series', 'Animated', 'Cancellation confirmed 11/26/19',\n       'S4 announced on 6/18/19', 'Two seasons picked up',\n       '2nd season in development', 'Potential 6th season on hold',\n       'Anime; rescheduled from April', 'Anthology series',\n       '3rd season unlikely (esp. in near future)',\n       'fka untitled Mindy Kaling comedy', 'First new season in 6 years',\n       'fka untitled Woody Allen series',\n       'S2 confirmed on 8/25/17; will air in 2019', 'Renwed 9/13/18',\n       'Project in jeopardy due to Ed Westwick scandal',\n       '3rd season of National Treasure anthology', 'Monthly anthology',\n       'Now a Hulu exclusive in the U.S.',\n       'Final 10-ep. 7th season in summer 2014',\n       'Returns after a 10-year absence', 'Will likely air in the fall',\n       'Previously picked up for a 2nd season', 'Returns on 2/14',\n       'Short (7-episode) season;  S8 to air in 2019',\n       'Alternate version released as an app in fall 2017',\n       '(4th season on HBO)', 'Reboot of 1980s anthology series',\n       '12-episode mini-season', 'Last aired on Fox in 2009',\n       'Production halted at 13 eps; off sched. after 12/3',\n       'In negotiations to return for 2017-18',\n       'Revival of the classic dating  show', '8th season announced 2/16',\n       \"Not on Fox's 2017-18 sched; presumed done\",\n       \"Won't be back in 2017, but could return in 2018\",\n       'No plans to revive the show again as of 5/14',\n       \"Not included in Fox's 2019-20 plans\", 'Game show',\n       'Will air in 2015-16 season', 'Short (6-episode) season',\n       'Short season (8 episodes)',\n       'A potential 2nd season is in development',\n       'S3 (Katrina) will now start in 2018-19',\n       'Rare fall season airs exclusively on CBS All Access',\n       'Pulled from  schedule on 4/19 with 5 eps unaired',\n       'CBS All-Access', 'Celebrity edition',\n       'Banished to Saturdays effective 5/4',\n       'Exclusive to CBS All Access', 'Syfy will air at least 2 seasons',\n       'Officially not progressing as a series 3/10',\n       'Syfy will air S1 & S2 of the web series',\n       '3rd season picked up by CW on 5/31/19',\n       \"fka One Day She'll Darken\", 'Sequel to The Spoils of Babylon',\n       'New title', 'Confirmed as a 1-season show prior to airing',\n       'Starz pulled out 3/2; may go elsewhere', 'American debut',\n       'Continuation of 1990-91 ABC series',\n       'Production halted as of June 2018',\n       'Will not return for a 2nd season',\n       '7 eps to air in 2014, final 7 in spring 2015', 'Anthology',\n       'Miniseres'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "df_tvstatus_popular_cleaning['status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [name, season, status, tv_network, ano, changed_network]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>season</th>\n      <th>status</th>\n      <th>tv_network</th>\n      <th>ano</th>\n      <th>changed_network</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "df_tvstatus_popular_cleaning[df_tvstatus_popular_cleaning['status'].str.contains('Pulled from schedule', flags=re.IGNORECASE, regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                name       season  \\\n331            The Spoils of Babylon          NaN   \n576                       Blunt Talk  Starts 8/22   \n633            Fear the Walking Dead   tbd August   \n1060                      Blunt Talk          NaN   \n1065             Brothers in Atlanta  starts  tbd   \n1493                 Vice Principals          NaN   \n1514                    Black Mirror     SEASON 3   \n1565              Skylanders Academy          NaN   \n1584                  The Grand Tour          NaN   \n1599                          Chance          NaN   \n1645                    Channel Zero          NaN   \n2258       The Marvelous Mrs. Maisel          NaN   \n2308                    The Alienist          NaN   \n2347                     Counterpart          NaN   \n2515                       X Company          NaN   \n2800  Chilling Adventures of Sabrina          NaN   \n2942           The Rise of Phoenixes          NaN   \n3038                      Homecoming          NaN   \n3142                      Dirty John          NaN   \n3346                        All Rise          NaN   \n3350                  Bob ♥ Abishola          NaN   \n3353              Carol's Second Act          NaN   \n3378                     The Unicorn          NaN   \n3741                  The Politician          NaN   \n3848                    Central Park          NaN   \n3857                The Morning Show          NaN   \n3924                 Solar Opposites          NaN   \n\n                                                 status          tv_network  \\\n331         Sequel ordered 7/7; will air in summer 2015                 IFC   \n576                          2nd season already ordered                STRZ   \n633                       Two seasons ordered on 3/9/15                 AMC   \n1060                         2nd season already ordered                STRZ   \n1065                     Series order rescinded on 1/22                 HBO   \n1493        Order is for 2 seasons; will end after that                 HBO   \n1514           Two seasons (S3 & S4) ordered by Netflix             Netflix   \n1565                    Original order is for 2 seasons             Netflix   \n1584                     Initial order is for 3 seasons        Amazon Prime   \n1599                     Initial order is for 2 seasons                Hulu   \n1645                       Anthology; 2 seasons ordered                SYFY   \n2258  Initial order is for 2 seasons; S3 renewal on ...  Amazon Prime Video   \n2308                  Sequel miniseries ordered 8/16/18                 TNT   \n2347                     Initial order is for 2 seasons                STRZ   \n2515                    Original order is for 3 seasons                OVAT   \n2800                     Initial order is for 2 seasons             Netflix   \n2942                   Chinese series; 70-episode order             Netflix   \n3038                     Initial order is for 2 seasons  Amazon Prime Video   \n3142      Initial order is for 2 seasons; moving to USA                BRAV   \n3346            Full-season order on 10/22; renewed 5/7                 CBS   \n3350            Full-season order on 10/22; renewed 5/7                 CBS   \n3353           Full-season order on 10/22; canceled 5/7                 CBS   \n3378            Full-season order on 10/22; renewed 5/7                 CBS   \n3741                     Initial order is for 2 seasons             Netflix   \n3848                    Initial  order is for 2 seasons           Apple TV+   \n3857                    Initial  order is for 2 seasons           Apple TV+   \n3924           Animated; initial order is for 2 seasons                Hulu   \n\n       ano  \n331   2013  \n576   2014  \n633   2014  \n1060  2015  \n1065  2015  \n1493  2016  \n1514  2016  \n1565  2016  \n1584  2016  \n1599  2016  \n1645  2016  \n2258  2017  \n2308  2017  \n2347  2017  \n2515  2017  \n2800  2018  \n2942  2018  \n3038  2018  \n3142  2018  \n3346  2019  \n3350  2019  \n3353  2019  \n3378  2019  \n3741  2019  \n3848  2019  \n3857  2019  \n3924  2019  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>season</th>\n      <th>status</th>\n      <th>tv_network</th>\n      <th>ano</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>331</th>\n      <td>The Spoils of Babylon</td>\n      <td>NaN</td>\n      <td>Sequel ordered 7/7; will air in summer 2015</td>\n      <td>IFC</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>576</th>\n      <td>Blunt Talk</td>\n      <td>Starts 8/22</td>\n      <td>2nd season already ordered</td>\n      <td>STRZ</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>633</th>\n      <td>Fear the Walking Dead</td>\n      <td>tbd August</td>\n      <td>Two seasons ordered on 3/9/15</td>\n      <td>AMC</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>1060</th>\n      <td>Blunt Talk</td>\n      <td>NaN</td>\n      <td>2nd season already ordered</td>\n      <td>STRZ</td>\n      <td>2015</td>\n    </tr>\n    <tr>\n      <th>1065</th>\n      <td>Brothers in Atlanta</td>\n      <td>starts  tbd</td>\n      <td>Series order rescinded on 1/22</td>\n      <td>HBO</td>\n      <td>2015</td>\n    </tr>\n    <tr>\n      <th>1493</th>\n      <td>Vice Principals</td>\n      <td>NaN</td>\n      <td>Order is for 2 seasons; will end after that</td>\n      <td>HBO</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>1514</th>\n      <td>Black Mirror</td>\n      <td>SEASON 3</td>\n      <td>Two seasons (S3 &amp; S4) ordered by Netflix</td>\n      <td>Netflix</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>1565</th>\n      <td>Skylanders Academy</td>\n      <td>NaN</td>\n      <td>Original order is for 2 seasons</td>\n      <td>Netflix</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>1584</th>\n      <td>The Grand Tour</td>\n      <td>NaN</td>\n      <td>Initial order is for 3 seasons</td>\n      <td>Amazon Prime</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>1599</th>\n      <td>Chance</td>\n      <td>NaN</td>\n      <td>Initial order is for 2 seasons</td>\n      <td>Hulu</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>1645</th>\n      <td>Channel Zero</td>\n      <td>NaN</td>\n      <td>Anthology; 2 seasons ordered</td>\n      <td>SYFY</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>2258</th>\n      <td>The Marvelous Mrs. Maisel</td>\n      <td>NaN</td>\n      <td>Initial order is for 2 seasons; S3 renewal on ...</td>\n      <td>Amazon Prime Video</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>2308</th>\n      <td>The Alienist</td>\n      <td>NaN</td>\n      <td>Sequel miniseries ordered 8/16/18</td>\n      <td>TNT</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>2347</th>\n      <td>Counterpart</td>\n      <td>NaN</td>\n      <td>Initial order is for 2 seasons</td>\n      <td>STRZ</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>2515</th>\n      <td>X Company</td>\n      <td>NaN</td>\n      <td>Original order is for 3 seasons</td>\n      <td>OVAT</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>2800</th>\n      <td>Chilling Adventures of Sabrina</td>\n      <td>NaN</td>\n      <td>Initial order is for 2 seasons</td>\n      <td>Netflix</td>\n      <td>2018</td>\n    </tr>\n    <tr>\n      <th>2942</th>\n      <td>The Rise of Phoenixes</td>\n      <td>NaN</td>\n      <td>Chinese series; 70-episode order</td>\n      <td>Netflix</td>\n      <td>2018</td>\n    </tr>\n    <tr>\n      <th>3038</th>\n      <td>Homecoming</td>\n      <td>NaN</td>\n      <td>Initial order is for 2 seasons</td>\n      <td>Amazon Prime Video</td>\n      <td>2018</td>\n    </tr>\n    <tr>\n      <th>3142</th>\n      <td>Dirty John</td>\n      <td>NaN</td>\n      <td>Initial order is for 2 seasons; moving to USA</td>\n      <td>BRAV</td>\n      <td>2018</td>\n    </tr>\n    <tr>\n      <th>3346</th>\n      <td>All Rise</td>\n      <td>NaN</td>\n      <td>Full-season order on 10/22; renewed 5/7</td>\n      <td>CBS</td>\n      <td>2019</td>\n    </tr>\n    <tr>\n      <th>3350</th>\n      <td>Bob ♥ Abishola</td>\n      <td>NaN</td>\n      <td>Full-season order on 10/22; renewed 5/7</td>\n      <td>CBS</td>\n      <td>2019</td>\n    </tr>\n    <tr>\n      <th>3353</th>\n      <td>Carol's Second Act</td>\n      <td>NaN</td>\n      <td>Full-season order on 10/22; canceled 5/7</td>\n      <td>CBS</td>\n      <td>2019</td>\n    </tr>\n    <tr>\n      <th>3378</th>\n      <td>The Unicorn</td>\n      <td>NaN</td>\n      <td>Full-season order on 10/22; renewed 5/7</td>\n      <td>CBS</td>\n      <td>2019</td>\n    </tr>\n    <tr>\n      <th>3741</th>\n      <td>The Politician</td>\n      <td>NaN</td>\n      <td>Initial order is for 2 seasons</td>\n      <td>Netflix</td>\n      <td>2019</td>\n    </tr>\n    <tr>\n      <th>3848</th>\n      <td>Central Park</td>\n      <td>NaN</td>\n      <td>Initial  order is for 2 seasons</td>\n      <td>Apple TV+</td>\n      <td>2019</td>\n    </tr>\n    <tr>\n      <th>3857</th>\n      <td>The Morning Show</td>\n      <td>NaN</td>\n      <td>Initial  order is for 2 seasons</td>\n      <td>Apple TV+</td>\n      <td>2019</td>\n    </tr>\n    <tr>\n      <th>3924</th>\n      <td>Solar Opposites</td>\n      <td>NaN</td>\n      <td>Animated; initial order is for 2 seasons</td>\n      <td>Hulu</td>\n      <td>2019</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "df_tvstatus[df_tvstatus['status'].str.contains('order', flags=re.IGNORECASE, regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [name, season, status, tv_network, ano, changed_network]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>season</th>\n      <th>status</th>\n      <th>tv_network</th>\n      <th>ano</th>\n      <th>changed_network</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "df_tvstatus_popular_cleaning[df_tvstatus_popular_cleaning['changed_network'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "               name       season  \\\n102   American Dad!  SEASON 9/10   \n548   American Dad!    SEASON 11   \n1033  American Dad!    SEASON 11   \n1613  American Dad!    SEASON 12   \n2311  American Dad!    SEASON 13   \n2312  American Dad!    SEASON 14   \n3104  American Dad!    SEASON 15   \n3936  American Dad!    SEASON 15   \n\n                                              status tv_network   ano  \n102   Final season on  Fox; moves to  TBS in 2014-15        Fox  2013  \n548               Renewed for a 12th season on 11/18        TBS  2014  \n1033        Renewed for 2 additional seasons on 8/27        TBS  2015  \n1613                  Previously renewed through S13        TBS  2016  \n2311                                             NaN        TBS  2017  \n2312                  Renewed through S16 on 1/11/18        TBS  2017  \n3104                  Previously renewed through S16        TBS  2018  \n3936                                             NaN        TBS  2019  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>season</th>\n      <th>status</th>\n      <th>tv_network</th>\n      <th>ano</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>102</th>\n      <td>American Dad!</td>\n      <td>SEASON 9/10</td>\n      <td>Final season on  Fox; moves to  TBS in 2014-15</td>\n      <td>Fox</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>548</th>\n      <td>American Dad!</td>\n      <td>SEASON 11</td>\n      <td>Renewed for a 12th season on 11/18</td>\n      <td>TBS</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>1033</th>\n      <td>American Dad!</td>\n      <td>SEASON 11</td>\n      <td>Renewed for 2 additional seasons on 8/27</td>\n      <td>TBS</td>\n      <td>2015</td>\n    </tr>\n    <tr>\n      <th>1613</th>\n      <td>American Dad!</td>\n      <td>SEASON 12</td>\n      <td>Previously renewed through S13</td>\n      <td>TBS</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>2311</th>\n      <td>American Dad!</td>\n      <td>SEASON 13</td>\n      <td>NaN</td>\n      <td>TBS</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>2312</th>\n      <td>American Dad!</td>\n      <td>SEASON 14</td>\n      <td>Renewed through S16 on 1/11/18</td>\n      <td>TBS</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>3104</th>\n      <td>American Dad!</td>\n      <td>SEASON 15</td>\n      <td>Previously renewed through S16</td>\n      <td>TBS</td>\n      <td>2018</td>\n    </tr>\n    <tr>\n      <th>3936</th>\n      <td>American Dad!</td>\n      <td>SEASON 15</td>\n      <td>NaN</td>\n      <td>TBS</td>\n      <td>2019</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "df_tvstatus[df_tvstatus['name'].str.contains('American Dad!', flags=re.IGNORECASE, regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "               name       season   status tv_network   ano  changed_network\n1878  American Dad!  SEASON 9/10  RENEWED        FOX  2013            False",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>season</th>\n      <th>status</th>\n      <th>tv_network</th>\n      <th>ano</th>\n      <th>changed_network</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1878</th>\n      <td>American Dad!</td>\n      <td>SEASON 9/10</td>\n      <td>RENEWED</td>\n      <td>FOX</td>\n      <td>2013</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "df_tvstatus_popular_cleaning[df_tvstatus_popular_cleaning['name'].str.contains('American Dad!', flags=re.IGNORECASE, regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df_tvstatus_popular_cleaning[['name', 'season', 'status', 'tv_network', 'ano', 'changed_network']].groupby(df_tvstatus_popular_cleaning['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-c1d6cb31f02c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_grouped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mdescribe\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_group_selection_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.chained_assignment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selected_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0;31m# gh-20949\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f, data)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mapplying\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \"\"\"\n\u001b[0;32m--> 892\u001b[0;31m         \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         return self._wrap_applied_output(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    177\u001b[0m         ):\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                 \u001b[0mresult_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mlibreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidApply\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mfast_apply\u001b[0;34m(self, f, sdata, names)\u001b[0m\n\u001b[1;32m    963\u001b[0m         \u001b[0;31m# must return keys::list, values::list, mutated::bool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlibreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_frame_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_chop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.apply_frame_axis0\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1627\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_group_selection_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdescribe\u001b[0;34m(self, percentiles, include, exclude, datetime_is_numeric)\u001b[0m\n\u001b[1;32m  10093\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10095\u001b[0;31m         \u001b[0mldesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdescribe_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10096\u001b[0m         \u001b[0;31m# set a convenient order for rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10097\u001b[0m         \u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m  10093\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10095\u001b[0;31m         \u001b[0mldesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdescribe_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10096\u001b[0m         \u001b[0;31m# set a convenient order for rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10097\u001b[0m         \u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdescribe_1d\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m  10073\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdescribe_numeric_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10074\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10075\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdescribe_categorical_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10077\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdescribe_categorical_1d\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m  10007\u001b[0m             \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"count\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"unique\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10008\u001b[0m             \u001b[0mobjcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10009\u001b[0;31m             \u001b[0mcount_unique\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobjcounts\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10010\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_unique\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10011\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only compare identically-labeled Series objects\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mlvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36mextract_array\u001b[0;34m(obj, extract_numpy)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mextract_numpy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCPandasArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/arrays/numpy_.py\u001b[0m in \u001b[0;36mto_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mna_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_grouped.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            name    season   status tv_network   ano  changed_network\n2531  12 Monkeys       NaN  RENEWED       SYFY  2014            False\n2548  12 Monkeys  SEASON 2  RENEWED       SYFY  2015            False\n2560  12 Monkeys  SEASON 3  RENEWED       SYFY  2016            False\n2585  12 Monkeys  SEASON 4      END       SYFY  2018            False",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>season</th>\n      <th>status</th>\n      <th>tv_network</th>\n      <th>ano</th>\n      <th>changed_network</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2531</th>\n      <td>12 Monkeys</td>\n      <td>NaN</td>\n      <td>RENEWED</td>\n      <td>SYFY</td>\n      <td>2014</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2548</th>\n      <td>12 Monkeys</td>\n      <td>SEASON 2</td>\n      <td>RENEWED</td>\n      <td>SYFY</td>\n      <td>2015</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2560</th>\n      <td>12 Monkeys</td>\n      <td>SEASON 3</td>\n      <td>RENEWED</td>\n      <td>SYFY</td>\n      <td>2016</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2585</th>\n      <td>12 Monkeys</td>\n      <td>SEASON 4</td>\n      <td>END</td>\n      <td>SYFY</td>\n      <td>2018</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "df_tvstatus_popular_cleaning[df_tvstatus_popular_cleaning['name'].str.contains('12 Monkeys', flags=re.IGNORECASE, regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit8187c9110e0b4b26a93ccac805d1391d",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}